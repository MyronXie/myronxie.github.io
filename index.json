[{"authors":null,"categories":null,"content":"Hello! I am Mingye Xie(Ë∞¢Èì≠ÁÉ®).\nI have received the B. Sc. degree from East China Normal University, China, in 2016, the M. Eng. Degree in electronics and communications engineering from East China Normal University, China, in 2019.\nI am currently pursing Ph. D. degree in computer science and technology from Shanghai Jiao Tong University, China.\nMy research interests include Generative Adversial Network (GAN) and Embedded System.\n","date":1646524800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1646524800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hello! I am Mingye Xie(Ë∞¢Èì≠ÁÉ®). I have received the B. Sc. degree from East China Normal University, China, in 2016, the M.","tags":null,"title":"Mingye Xie","type":"authors"},{"authors":["Mingye Xie","Suncheng Xiang","Feng Wang","Ting Liu","Yuzhuo Fu"],"categories":null,"content":"","date":1646524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646524800,"objectID":"fc08f3ed02759b76a8a59d61b18836c1","permalink":"https://myronxie.github.io/publication/xie2022spatial/","publishdate":"2022-03-06T00:00:00Z","relpermalink":"/publication/xie2022spatial/","section":"publication","summary":"Facial attribute manipulation has attracted great attention from the public due to its wide range of applications. Aiming to smoothly manipulate the attributes of real facial images, it is critical to search a proper latent code aligns with the domain of pre-trained GAN for faithful inversion and control the transformation within the scope of the attribute for precise editing. Previous methods mainly focused on improving the quality of reconstruction, but often ignored the editing effect. To address this issue, we first propose a mapping network to manipulate latent code which is effective for diverse situations, and design a spatial attention network to predict binary mask of certain attribute which encourages to only alter relevant region of images and suppress irrelevant changes. In addition, we introduce a novel latent space into GAN inversion framework which achieves high reconstruction quality especially preserving identity features and retains ability to edit face attributes. Our methods pave the way to semantically meaningful and disentangled manipulations on both generated images and real images. Experimental results indicate a clear improvement over the current state-of-the-art methods both in subjective and objective metrics.","tags":["Generative adversarial network (GAN)","Facial attribute manipulation","Attention mechanism"],"title":"Spatial Attention Guided Local Facial Attribute Editing","type":"publication"},{"authors":null,"categories":["Academic"],"content":"We first propose a mapping network to manipulate latent code which is effective for diverse situations, and design a spatial attention network to predict binary mask of certain attribute which encourages to only alter relevant region of images and suppress irrelevant changes.\nIn addition, we introduce a novel latent space into GAN inversion framework which achieves high reconstruction quality especially preserving identity features and retains ability to edit face attributes.\nSpatial thanks to Feng Wang for model building.\n","date":1646524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646524800,"objectID":"21f9457cd3a7c9c7da511b503d684a36","permalink":"https://myronxie.github.io/post/2022-03-face-editing/","publishdate":"2022-03-06T00:00:00Z","relpermalink":"/post/2022-03-face-editing/","section":"post","summary":"About face editing. Please refer to [Here](./publication/xie2022spatial/) for more information.","tags":["Academic"],"title":"üßê One paper is accepted in ICME 2022!","type":"post"},{"authors":["Mingye Xie","Ting Liu","Yuzhuo Fu"],"categories":null,"content":"","date":1642809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642809600,"objectID":"fd87377041c5d18ea988a39a11380001","permalink":"https://myronxie.github.io/publication/xie2022gos/","publishdate":"2022-01-31T00:00:00Z","relpermalink":"/publication/xie2022gos/","section":"publication","summary":"Scene editing has attracted increasing research interests owing to its valuable applications in the field of photography, entertainment. With style-based GAN being proposed, images can be reasonably edited on specific semantic by manipulating in latent space of generator. However, existing datasets cannot satisfy the demands of large amounts of diverse data and rich semantic annotations at the same time, which makes the existing method difficult to edit on the content of outdoor scene images. To address these problems, we propose a large-scale, diverse synthetic dataset called ``GOS dataset\" generated based on video game, which contains fine-grained semantic annotations. Extensive experiments show that utilizing the features obtained from the annotations of our dataset achieves better performance in outdoor scene editing, especially for distance and viewpoint of scenes, which indicates the extracted features have a certain generalization capability.","tags":["Generative adversarial network (GAN)","Synthetic data generation","Scene editing"],"title":"GOS: A Large-Scale Annotated Outdoor Scene Synthetic Dataset","type":"publication"},{"authors":null,"categories":["Academic"],"content":"We propose a large-scale, diverse synthetic dataset called \u0026ldquo;GOS dataset\u0026rdquo; generated based on video game, which contains fine-grained semantic annotations.\nDetailed information and samples about the dataset is available online at https://myronxie.github.io/GOS/.\n","date":1631750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645056000,"objectID":"23b9d0a06b370216bb2552f1740b08a3","permalink":"https://myronxie.github.io/post/2021-09-gos-dataset/","publishdate":"2021-09-16T00:00:00Z","relpermalink":"/post/2021-09-gos-dataset/","section":"post","summary":"Please refer to https://myronxie.github.io/GOS/ for more information.","tags":["Academic"],"title":"üèôÔ∏è GOS is accepted in ICASSP 2022!","type":"post"},{"authors":["Suncheng Xiang","Yuzhuo Fu","Mingye Xie","Zefang Yu","Ting Liu"],"categories":null,"content":"","date":1585526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585526400,"objectID":"a917c5b00efb67f46236e97218e95f67","permalink":"https://myronxie.github.io/publication/xiang2020unsupervised/","publishdate":"2020-03-30T00:00:00Z","relpermalink":"/publication/xiang2020unsupervised/","section":"publication","summary":"Person re-identification (re-ID) has recently been tremendously boosted due to the advancement of deep convolutional neural networks. Unfortunately, the majority of deep re-ID methods focus on supervised, single-domain re-ID task, while less attention is paid on unsupervised domain adaptation. Therefore, these methods always fail to generalize well to real-world scenarios, which have attracted much attention from academia. To address this challenge, we propose a joint unsupervised domain adaptive re-ID method, named HCTL, which is aided by Hierarchical Clustering and Transfer Learning. Specifically, our method performs camera invariance learning using iStarGAN by transferring style of reliable images, which is mined by hierarchical clustering, to the style of other cameras in target domain. During training stage, HCTL integrates TriHard loss on top of ResNet-50 to reduce intra-class variance among dataset and enforce connectedness simultaneously between source domain and target domain. Comprehensive experiments based on Market-1501, DukeMTMC-reID and CUHK03 are conducted, results indicate that our method robustly achieves state-of-the-art performances with only a few reliable samples in target domain and outperform any existing approaches by a large margin.","tags":[],"title":"Unsupervised person re-identification by hierarchical cluster and domain transfer","type":"publication"},{"authors":["Xin Xie","Songlin Ge","Fengping Hu","Mingye Xie","Nan Jiang"],"categories":null,"content":"","date":1550188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550188800,"objectID":"25968ed992d5a612f4c79ccab5658c2c","permalink":"https://myronxie.github.io/publication/xie2019improved/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/publication/xie2019improved/","section":"publication","summary":"Sentiment analysis is an important field of study in natural language processing. In the massive data and irregular data, sentiment classification with high accuracy is a major challenge in sentiment analysis. To address this problem, a novel maximum entropy-PLSA model is proposed. In this model, we first use the probabilistic latent semantic analysis to extract the seed emotion words from the Wikipedia and the training corpus. Then features are extracted from these seed emotion words, which are the input of the maximum entropy model for training the maximum entropy model. The test set is processed similarly into the maximum entropy model for emotional classification. Meanwhile, the training set and the test set are divided by the K-fold method. The maximum entropy classification based on probabilistic latent semantic analysis uses important emotional classification features to classify words, such as the relevance of words and parts of speech in the context, the relevance with degree adverbs, the similarity with the benchmark emotional words and so on. The experiments prove that the classification method proposed by this paper outperforms the compared methods.","tags":[],"title":"An improved algorithm for sentiment analysis based on maximum entropy","type":"publication"},{"authors":["Xin Xie","Songlin Ge","Mingye Xie","Fengping Hu","Nan Jiang"],"categories":null,"content":"","date":1550188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550188800,"objectID":"51630fb204e28bc1ed569e4e18a5b529","permalink":"https://myronxie.github.io/publication/xie2020improved/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/publication/xie2020improved/","section":"publication","summary":"In this paper, an improved sub-pixel edge detection algorithm combining coarse and precise location is proposed. The algorithm fully considers the 8-neighborhood pixel information and keeps the Roberts operator‚Äôs advantages of high location accuracy and fast speed. Meanwhile, it can effectively suppress noise and obtain better detection results. In order to solve the problem of low efficiency of the Zernike moment method in threshold selection, the Otsu‚Äôs method is introduced to achieve accurate sub-pixel edge location. The experimental results show that the proposed algorithm effectively improves the detection efficiency and the detection accuracy.","tags":[],"title":"Image matching algorithm of defects on navel orange surface based on compressed sensing","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://myronxie.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"In recent years, multi-rotor UAVs have shown great application value in the fields of aerial photography, power inspection, and agricultural plant protection due to their simple structure, convenient use and easy maintenance. With the continuous investment of commercial companies, research institutes and open source communities, the technology related to multi-rotor drones has developed vigorously.\nThe sensor system, as part of a multi-rotor drone, continuously provides reliable sensor raw data for the drone. The sensor data is finally converted into state information such as flight attitude and flight position of the drone through various algorithms within the system, which provides a basis for the multi-rotor UAV to achieve autonomous control. This paper uses the Pixhawk open source flight control system, based on the self-designed and built flight control software and hardware platform, the following research and design of the multi-rotor UAV sensor system:\n The selection of sensor hardware was studied and evaluated. By comparing and verifying the performance parameters of each sensor, the MEMS sensor selection suitable for multi-rotor UAVs was selected. Research and implementation of sensor data processing algorithms. By analyzing the sensor error source and error type, the corresponding error model is established, and data processing methods such as data calibration processing, temperature compensation processing and data filtering processing are introduced according to this model to reduce the correlation error to the sensor data. The sensor data fusion algorithm and the UAV attitude calculation algorithm are studied and implemented. The multi-sensor fusion mechanism avoids the impact of a single sensor failure on the sensor system. Different types of sensor information are fused by introducing corresponding complementary filtering algorithms to reduce the error that occurs when the UAV attitude is solved.  Through the above research and design, the sensor system can obtain more accurate and stable sensor raw data, which enables the flight control system to solve more accurate attitude information, and finally make the multi-rotor drone maintain a more stable flight.\n","date":1548892800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548892800,"objectID":"4c5695742822dc2fb29d30d3392ae27f","permalink":"https://myronxie.github.io/project/master-thesis/","publishdate":"2019-01-31T00:00:00Z","relpermalink":"/project/master-thesis/","section":"project","summary":"Master Thesis","tags":["Thesis"],"title":"Research and Design of Multi-rotor UAV Sensor System Based on Pixhawk","type":"project"},{"authors":null,"categories":null,"content":"From Sep 2017 to Oct 2018.\nParticipate in the writing and testing of multi-rotor UAV accompanying computer embedded control software. Accompanying the computer using STM32F3 as the main control chip, its main functions are: controlling the onboard landing gear to carry out the retracting operation smoothly; controlling the power state of the onboard smart battery, and real-time collection of battery voltage, current, power and other related information; establishment Two-way communication with the drone\u0026rsquo;s onboard flight controller, receiving control signals to control the landing gear and smart battery, and sending the status information of the onboard equipment.\nParticipate in the writing and testing of the software and hardware of the multi-rotor UAV flight controller. The flight control software is written in a Unix-like environment. The main tasks include: Responsible for the driver writing and testing of UAV airborne sensors; research and optimize sensor data acquisition algorithms, processing algorithms and fusion algorithms, improve the stability of UAV attitude calculation; test flight controller hardware circuit boards Reliability, and make suggestions for improvement based on the problems encountered.\nAssist in the completion of other embedded-related projects within the company: a smart car that can run on a preset route through a remote control handle and take pictures of the goods on the shelf; monitor the vibration of the vibration state of each mechanical part of the drone through multiple accelerometers Recorder etc.\n","date":1539561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539561600,"objectID":"3f16f110ee75eb68b69cc33e5439fee9","permalink":"https://myronxie.github.io/project/clobotics/","publishdate":"2018-10-15T00:00:00Z","relpermalink":"/project/clobotics/","section":"project","summary":"As Embedded Software Assistant from Sep 2017 to Oct 2018.","tags":["Internship"],"title":"Internship in Clobotics","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://myronxie.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]