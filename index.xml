<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mingye Xie&#39;s Homepage</title>
    <link>https://myronxie.github.io/</link>
      <atom:link href="https://myronxie.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Mingye Xie&#39;s Homepage</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://myronxie.github.io/media/icon_hu15489444370759105925.png</url>
      <title>Mingye Xie&#39;s Homepage</title>
      <link>https://myronxie.github.io/</link>
    </image>
    
    <item>
      <title>GPA: Enhancing Generalizable Physical Adversarial Attacks Across Multiple Vision Tasks</title>
      <link>https://myronxie.github.io/publication/xie2025gpa/</link>
      <pubDate>Sat, 21 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/xie2025gpa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>GIST: Improving Parameter Efficient Fine-Tuning via Knowledge Interaction</title>
      <link>https://myronxie.github.io/publication/ruan2024gist/</link>
      <pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/ruan2024gist/</guid>
      <description></description>
    </item>
    
    <item>
      <title>iDAT: inverse Distillation Adapter-Tuning</title>
      <link>https://myronxie.github.io/publication/ruan2024idat/</link>
      <pubDate>Sun, 14 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/ruan2024idat/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SubFace: learning with softmax approximation for face recognition</title>
      <link>https://myronxie.github.io/publication/xiang2024subface/</link>
      <pubDate>Thu, 04 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/xiang2024subface/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning to Floorplan like Human Experts via Reinforcement Learning</title>
      <link>https://myronxie.github.io/publication/yan2024learning/</link>
      <pubDate>Fri, 01 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/yan2024learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Raw Video to Pedagogical Insights: A Unified Framework for Student Behavior Analysis</title>
      <link>https://myronxie.github.io/publication/yu2024from/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/yu2024from/</guid>
      <description></description>
    </item>
    
    <item>
      <title>LAMM: Label Alignment for Multi-Modal Prompt Learning</title>
      <link>https://myronxie.github.io/publication/gao2024lamm/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/gao2024lamm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>GhostFormer: Efficiently amalgamated CNN-transformer architecture for object detection</title>
      <link>https://myronxie.github.io/publication/xie2024ghostformer/</link>
      <pubDate>Fri, 01 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/xie2024ghostformer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Editing outdoor scenes with a large annotated synthetic dataset</title>
      <link>https://myronxie.github.io/publication/xie2023editing/</link>
      <pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/xie2023editing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>EGE-UNet: an Efficient Group Enhanced UNet for skin lesion segmentation</title>
      <link>https://myronxie.github.io/publication/ruan2023ege/</link>
      <pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/ruan2023ege/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MALUNet: A Multi-Attention and Light-weight UNet for Skin Lesion Segmentation</title>
      <link>https://myronxie.github.io/publication/ruan2022malunet/</link>
      <pubDate>Thu, 20 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/ruan2022malunet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>📑 Reviewer Assignment</title>
      <link>https://myronxie.github.io/post/2022-08-reviewer/</link>
      <pubDate>Tue, 09 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/post/2022-08-reviewer/</guid>
      <description>&lt;p&gt;[2024/01] I served as a reviewer of 2024 IEEE International Conference on Multimedia and Expo (ICME 2024).&lt;/p&gt;
&lt;p&gt;[2023/05] I served as a reviewer of 31st ACM International Conference on Multimedia (ACM MM 2023).&lt;/p&gt;
&lt;p&gt;[2022/08] I served as a reviewer of Expert Systems With Applications (ESWA).&lt;/p&gt;
&lt;p&gt;[2022/06] I served as a reviewer of 4th International Conference on Machine Learning for Cyber Security (ML4CS 2022).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spatial Attention Guided Local Facial Attribute Editing</title>
      <link>https://myronxie.github.io/publication/xie2022spatial/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/xie2022spatial/</guid>
      <description></description>
    </item>
    
    <item>
      <title>🧐 One paper is accepted in ICME 2022!</title>
      <link>https://myronxie.github.io/post/2022-03-face-editing/</link>
      <pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/post/2022-03-face-editing/</guid>
      <description>&lt;p&gt;We first propose a mapping network to manipulate latent code which is effective for diverse situations, and design a spatial attention network to predict binary mask of certain attribute which encourages to only alter relevant region of images and suppress irrelevant changes.&lt;/p&gt;
&lt;p&gt;In addition, we introduce a novel latent space into GAN inversion framework which achieves high reconstruction quality especially preserving identity features and retains ability to edit face attributes.&lt;/p&gt;
&lt;p&gt;Spatial thanks to Feng Wang for model building.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GOS: A Large-Scale Annotated Outdoor Scene Synthetic Dataset</title>
      <link>https://myronxie.github.io/publication/xie2022gos/</link>
      <pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/xie2022gos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Patents &amp; Copyright of computer software</title>
      <link>https://myronxie.github.io/project/patent/</link>
      <pubDate>Fri, 15 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/project/patent/</guid>
      <description>&lt;h3 id=&#34;发明专利-patent&#34;&gt;发明专利 (Patent)&lt;/h3&gt;
&lt;p&gt;基于视觉识别的精密轴尺寸测量方法、装置和系统&lt;br&gt;
国家发明专利（专利号：ZL201810042093.2）&lt;br&gt;
谢昕，谢铭烨，胡锋平，王伟如，江勋绎&lt;/p&gt;
&lt;h3 id=&#34;软件著作权-copyright-of-computer-software&#34;&gt;软件著作权 (Copyright of computer software)&lt;/h3&gt;
&lt;p&gt;非接触式触控屏控制软件&lt;br&gt;
软件著作权（登记号：2018SR522061）&lt;br&gt;
谢铭烨，金豫，等&lt;br&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>🏙️ GOS is accepted in ICASSP 2022!</title>
      <link>https://myronxie.github.io/post/2021-09-gos-dataset/</link>
      <pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/post/2021-09-gos-dataset/</guid>
      <description>&lt;p&gt;We propose a large-scale, diverse synthetic dataset called &amp;ldquo;&lt;strong&gt;GOS&lt;/strong&gt; dataset&amp;rdquo; generated based on video game, which contains fine-grained semantic annotations.&lt;/p&gt;
&lt;p&gt;Detailed information and samples about the dataset is available online at &lt;a href=&#34;https://myronxie.github.io/GOS/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://myronxie.github.io/GOS/&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unsupervised person re-identification by hierarchical cluster and domain transfer</title>
      <link>https://myronxie.github.io/publication/xiang2020unsupervised/</link>
      <pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/xiang2020unsupervised/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An improved algorithm for sentiment analysis based on maximum entropy</title>
      <link>https://myronxie.github.io/publication/xie2019improved/</link>
      <pubDate>Fri, 15 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/xie2019improved/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image matching algorithm of defects on navel orange surface based on compressed sensing</title>
      <link>https://myronxie.github.io/publication/xie2020improved/</link>
      <pubDate>Fri, 15 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/publication/xie2020improved/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://myronxie.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-hugo-blox-builder&#34;&gt;Create slides in Markdown with Hugo Blox Builder&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://hugoblox.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugo Blox Builder&lt;/a&gt; | &lt;a href=&#34;https://docs.hugoblox.com/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://revealjs.com/pdf-export/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;porridge&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;blueberry&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Eating...&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} One {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} **Two** {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% fragment %}} Three {{% /fragment %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
  One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  &lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
  Three
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{% speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Only the speaker can read these notes
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;-&lt;/span&gt; Press &lt;span class=&#34;sb&#34;&gt;`S`&lt;/span&gt; key to view
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  {{% /speaker_note %}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/media/boards.jpg&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;background-color&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;#0000FF&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{{&lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;slide&lt;/span&gt; &lt;span class=&#34;na&#34;&gt;class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;my-style&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;}}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-css&#34; data-lang=&#34;css&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;reveal&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;section&lt;/span&gt; &lt;span class=&#34;nt&#34;&gt;h3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;color&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;navy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://discord.gg/z8wNYzb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.hugoblox.com/content/slides/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Master Thesis</title>
      <link>https://myronxie.github.io/project/master-thesis/</link>
      <pubDate>Thu, 31 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/project/master-thesis/</guid>
      <description>&lt;p&gt;Research and Design of Multi-rotor UAV Sensor System Based on Pixhawk (Master Thesis)&lt;/p&gt;
&lt;p&gt;In recent years, multi-rotor UAVs have shown great application value in the fields of aerial photography, power inspection, and agricultural plant protection due to their simple structure, convenient use and easy maintenance. With the continuous investment of commercial companies, research institutes and open source communities, the technology related to multi-rotor drones has developed vigorously.&lt;/p&gt;
&lt;p&gt;The sensor system, as part of a multi-rotor drone, continuously provides reliable sensor raw data for the drone. The sensor data is finally converted into state information such as flight attitude and flight position of the drone through various algorithms within the system, which provides a basis for the multi-rotor UAV to achieve autonomous control.
This paper uses the Pixhawk open source flight control system, based on the self-designed and built flight control software and hardware platform, the following research and design of the multi-rotor UAV sensor system:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The selection of sensor hardware was studied and evaluated. By comparing and verifying the performance parameters of each sensor, the MEMS sensor selection suitable for multi-rotor UAVs was selected.&lt;/li&gt;
&lt;li&gt;Research and implementation of sensor data processing algorithms. By analyzing the sensor error source and error type, the corresponding error model is established, and data processing methods such as data calibration processing, temperature compensation processing and data filtering processing are introduced according to this model to reduce the correlation error to the sensor data.&lt;/li&gt;
&lt;li&gt;The sensor data fusion algorithm and the UAV attitude calculation algorithm are studied and implemented. The multi-sensor fusion mechanism avoids the impact of a single sensor failure on the sensor system. Different types of sensor information are fused by introducing corresponding complementary filtering algorithms to reduce the error that occurs when the UAV attitude is solved.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Through the above research and design, the sensor system can obtain more accurate and stable sensor raw data, which enables the flight control system to solve more accurate attitude information, and finally make the multi-rotor drone maintain a more stable flight.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Internship in Clobotics</title>
      <link>https://myronxie.github.io/project/clobotics/</link>
      <pubDate>Mon, 15 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://myronxie.github.io/project/clobotics/</guid>
      <description>&lt;p&gt;From Sep 2017 to Oct 2018.&lt;/p&gt;
&lt;p&gt;Participate in the writing and testing of multi-rotor UAV accompanying computer embedded control software. Accompanying the computer using STM32F3 as the main control chip, its main functions are: controlling the onboard landing gear to carry out the retracting operation smoothly; controlling the power state of the onboard smart battery, and real-time collection of battery voltage, current, power and other related information; establishment Two-way communication with the drone&amp;rsquo;s onboard flight controller, receiving control signals to control the landing gear and smart battery, and sending the status information of the onboard equipment.&lt;/p&gt;
&lt;p&gt;Participate in the writing and testing of the software and hardware of the multi-rotor UAV flight controller. The flight control software is written in a Unix-like environment. The main tasks include: Responsible for the driver writing and testing of UAV airborne sensors; research and optimize sensor data acquisition algorithms, processing algorithms and fusion algorithms, improve the stability of UAV attitude calculation; test flight controller hardware circuit boards Reliability, and make suggestions for improvement based on the problems encountered.&lt;/p&gt;
&lt;p&gt;Assist in the completion of other embedded-related projects within the company: a smart car that can run on a preset route through a remote control handle and take pictures of the goods on the shelf; monitor the vibration of the vibration state of each mechanical part of the drone through multiple accelerometers Recorder etc.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
